[
  {
    "text": "* & Consulting De*nsul*ent & Code Reviews Trainings & Education Trainings Why learn from us? * ** & Consulting De*nsul*ent & Code Reviews Trainings & Education Trainings Why learn from us? * *ngular Node.js Fundamentals RisingStack Blog We’re a full-stack software development agency focusing on JavaScript, DevOps, Microservices & Kubernetes. For more info visit risingstack.com, or feel free to contact us! * Search Search Tags edited reviewed Download & Update Node.js to the Latest Version! Node v21.1.0 Current / LTS v20.9.0 Direct Links Ferenc Hámori Direct download links to update to the latest Node.js versions: Node v21.1.0 / LTS v20.9.0 Node.js 21 is here with Websocket RisingStack Engineering The latest major version of Node.js has just released with a few new interesting experimental features and a lot of fixes and optimization. You can The Best JavaScript Frameworks: Pros and Cons Explained RisingStack Engineering In this article, we’ll focus on the most popular JavaScript frameworks, and explore why they’re either loved or disliked by developers. ChatGPT use case examples for programming Ferenc Hámori Learn how we use GPT-based products as tools in a professional webdev setting. AI Development Tools Compared – The Differences You’ll Need to Know RisingStack Engineering There are many different types of AI development tools available, but not all of them are created equal. Some tools are more suited for certain Kubernetes Interview Questions and Answers You’ll Need the Most RisingStack Engineering Are you currently preparing for a Kubernetes interview? If so, you’ll want to make sure you’re familiar with the questions and answers below at least. RedwoodJS vs. BlitzJS: The Future of Fullstack JavaScript Meta-Frameworks Tamas Kadlecsik RedwoodJS & BlitzJS are meta-frameworks that provide tooling for creating SPAs, server-side rendered pages & statically generated content, providing a CLI to generate e2e scaffolds. Argo CD Kubernetes Tutorial Janos Kubisch With this Argo CD Kubernetes tutorial you’ll learn to store credentials safely within your k8s cluster using a pull-based continous deployment tool. How to Deploy a Ceph Storage to Bare Virtual Machines RisingStack Engineering The main drawback of a Ceph storage is that you have to host and manage it yourself. In this post, we’ll check two different approaches of deploying Ceph. Async Await in Node.js – How to Master it? Tamas Kadlecsik Learn how to use async await in Node.js (async functions) to simplify your callback or Promise based application. Sometimes you do need Kubernetes! But how should you decide? Tamas Kadlecsik A case study where the adoption of Kubernetes has been heavily contested. Learn about our decision making process, and how we overcame k8s’s limitations! Distributed Load Testing with Jmeter Janos Kubisch Learn how to distribute and run Jmeter tests along multiple droplets on DigitalOcean using Terraform, Ansible, and bash scripting – to automate the process. Node.js Async Best Practices & Avoiding the Callback Hell tamas-hodi This post covers what tools and techniques you have at your disposal when handling Node.js asynchronous operations. Learn how to avoid the callback hell ! Mammogram Analysis with AI and User-Friendly Interfaces Janos Kubisch See how RisingStack and Semmelweis University created an image recognition system using deep convolutional neural networks and a user-friendly interface for healthcare workers fighting against breast cancer. RisingStack News (formerly Microservice Weekly) – a hand-curated newsletter RisingStack Engineering Microservice Weekly, our newsletter about microservices had a great run – we’ve carefully curated the best sources we could find and sent out more than Do your engineers do what you think they do? Tamas Kadlecsik This case study shows how we reformed a scale-up’s dev processes after uncovering severe discrepancies between the official and real way of getting things done. History of JavaScript on a Timeline RisingStack Engineering In the early 1990s, Brendan Eich needed a scripting language for web pages that would be easy to use, so he created one himself. « Previous Page1 Page2 Page3 … Page22 Next » *e.js Consulting DevOps, SRE & Cloud Consul*ent & Code Re* for Software Developers * Building Complex Apps with A*.",
    "url": "https://blog.risingstack.com/"
  },
  {
    "text": "* & Consulting De*nsul*ent & Code Reviews Trainings & Education Trainings Why learn from us? * ** & Consulting De*nsul*ent & Code Reviews Trainings & Education Trainings Why learn from us? * *ngular Node.js Fundamentals AI Development Tools Compared – The Differences You’ll Need to Know Last updated: February 2, 2023 *e.js Consulting De*ting 24.7 Node.js Support Infrastructu*i*es Learn more at risingstack.com * In this article: RisingStack Engineering There are many different types of AI development tools available, but not all of them are created equal. Some tools are more suited for certain tasks than others, and it’s important to select the right tool for the job. Choosing the wrong tool can lead to frustration and wasted time, so it’s important to do your research before you start coding. There are many different types of AI development tools available, so there’s sure to be one that fits your needs. Common types of AI development tools include cloud-based platforms, open source software, and low code development tools. Cloud-based platforms are typically the most user friendly and allow you to build sophisticated models quickly. They offer a wide variety of features, such as data analysis tools, natural language processing capabilities, automatic machine learning models creation and pre-trained models that can be used for various tasks. Open-source software offers a great deal of flexibility and the ability to customize your AI model for specific tasks. However, using open source software requires coding knowledge and experience and is best suited for more experienced developers. Low code development tools allow you to create AI applications without having to write code. These tools allow developers of any skill level to quickly and easily create AI applications, eliminating the need for coding knowledge or experience. Of course, there are occasional overlaps, like cloud platforms using open-source technologies – but to find out all the similarities and differences, we’ll need to examine them. Let’s explore each one in further detail: Detectron 2 Detectron 2 is Facebook’s state-of-the-art object detection and segmentation library. It features a number of pre-trained models and baselines that can be used for a variety of tasks, and it also has cuda bindings that allow it to run on gpu for even faster training. Compared to its predecessor, Detectron 2 is much faster to train and can achieve better performance on a variety of benchmarks. It is also open source and written in python, making it easy to use and extend. Overall, Detectron 2 is an excellent choice for any object detection or segmentation task. The fact that it is built on PyTorch makes it very easy to share models between different use cases. For example, a model that is developed for research purposes can be quickly transferred to a production environment. This makes Detectron2 ideal for organizations that need to move quickly and efficiently between different use cases. In addition, the library’s ability to handle large-scale datasets makes it perfect for organizations that need to process large amounts of data. Overall, Detectron2 is an extremely versatile tool that can be used in a variety of different settings. Caffe Caffe is a deep learning framework for model building and optimisation. It was originally focused on vision applications, but it is now branching out into other areas such as sequences, reinforcement learning, speech, and text. Caffe is written in C++ and CUDA, with interfaces for python and mathlab. The community has built a number of models which are available at https://github.com/BVLC/caffe/wiki/Model-Zoo. Caffe is a powerful tool for anyone interested in deep learning. It features fast, well-tested code and a seamless switch between CPU and GPU – meaning that if you don’t have a GPU that supports CUDA, it automatically defaults to the CPU. This makes it a versatile tool for deep learning researchers and practitioners. The Caffe framework is also open source, so anyone can contribute to its development. Caffe offers the model definitions, optimization settings, and pre-trained weights so you can start right away. The BVLC models are licensed for unrestricted use, so you can use them in your own projects without any restrictions. Keras Keras is a deep learning framework that enables fast experimentation. It is based on Python and supports multiple backends, including TensorFlow, CNTK, and Theano. Keras includes specific tools for computer vision (KerasCV) and natural language processing (KerasNLP). Keras is open source and released under the MIT license. The idea behind Keras is to provide a consistent interface to a range of different neural network architectures, allowing for easy and rapid prototyping. It is also possible to run Keras models on top of other lower-level frameworks such as MXNet, Deeplearning4j, TensorFlow or Theano. Keras, like other similar tools, has the advantage of being able to run on both CPU and GPU devices with very little modification to the code. In addition, Keras includes a number of key features such as support for weight sharing and layer reuse, which can help to improve model performance and reduce training time. CUDA The CUDA toolkit is a powerful set of tools from NVIDIA for running code on GPUs. It includes compilers, libraries, and other necessary components for developing GPU-accelerated applications. The toolkit supports programming in Python, C, and C++, and it makes it easy to take advantage of the massive parallel computing power of GPUs. With the CUDA toolkit, you can accelerate your code to run orders of magnitude faster than on a CPU alone. Whether you’re looking to speed up machine learning algorithms or render complex 3D graphics, the CUDA toolkit can help you get the most out of your NVIDIA GPUs. In the context of fraud detection, the CUDA toolkit can be used to train graph neural networks (GNNs) on large datasets in an efficient manner. This allows GNNs to learn from more data, which can lead to improved performance. In addition, the CUDA toolkit can be used to optimize the inference process, which is important for real-time applications such as fraud detection, which is a critical application for machine learning. Many techniques struggle with fraud detection because they cannot easily identify patterns that span multiple transactions. However, GNNs are well-suited to this task due to their ability to aggregate information from the local neighborhood of a transaction. This enables them to identify larger patterns that may be missed by traditional methods. TensorFlow TensorFlow is an open-source platform for machine learning that offers a full pipeline from model building to deployment. It has a large collection of pre-trained models and supports a broad range of programming languages including Javascript, Python, Android, Swift, C++, and Objective C. TensorFlow uses the Keras API and also supports CUDA for accelerated training on NVIDIA GPUs. In addition to providing tools for developers to build and train their own models, TensorFlow also offers a wide range of resources such as tutorials and guides. TensorFlow.js is a powerful tool that can be used to solve a variety of problems. In the consumer packaged goods (CPG) industry, one of the most common problems is real-time and offline SKU detection. This problem is often caused by errors in manually inputting data, such as when a product is scanned at a store or when an order is placed online. TensorFlow.js can be used to create a solution that would automatically detect and correct these errors in real time, as well as provide offline support for cases where a connection is not available. This can greatly improve the efficiency of the CPG industry and reduce the amount of waste caused by incorrect data input. PyTorch PyTorch is a powerful machine learning framework that allows developers to create sophisticated applications for computer vision, audio processing, and time series analysis. The framework is based on the popular Python programming language, and comes with a large number of libraries and frameworks for easily creating complex models and algorithms. PyTorch also supports bindings for c++ and java, making it a great option for cross-platform development. In addition, the framework includes CUDA support for accelerated computing on NVIDIA GPUs. And finally, PyTorch comes with a huge collection of pre-trained models that can be used for quickly building sophisticated applications. PyTorch’s ease of use and flexibility make it a popular choice for researchers and developers alike. The PyTorch framework is known to be convenient and flexible, with examples covering reinforcement learning, image classification, and natural language processing as the more common use cases. As a result, it is no surprise that the framework has been gaining popularity in recent years. Thanks to its many features and benefits, PyTorch looks poised to become the go-to framework for deep learning in the years to come. Apache MXNet MXNet is an open-source deep learning framework that allows you to define, train, and deploy deep neural networks on a wide array of devices, from cloud infrastructure to mobile devices. It’s scalable, allowing for fast model training, and supports a flexible programming model and multiple languages. It’s built on a dynamic dependency scheduler that automatically parallelizes both symbolic and imperative operations on the fly. A graph optimization layer makes symbolic execution fast and memory efficient. The MXNet library is portable and lightweight. It’s accelerated with the NVIDIA Pascal™ GPUs and scales across multiple GPUs and multiple nodes, allowing you to train models faster. Whether you’re looking to build state-of-the-art models for image classification, object detection, or machine translation, MXNet is the tool for you. Horovod Horovod is a distributed training framework for deep learning that supports TensorFlow, Keras, PyTorch, and Apache MXNet. It is designed to make distributed training easy to use and efficient. Horovod uses a message passing interface to communicate between nodes, and each node runs a copy of the training script. The framework handles the details of communication and synchronization between nodes so that users can focus on their model. Horovod also includes a number of optimizations to improve performance, such as automatically fusing small tensors together and using hierarchical allreduce to reduce network traffic. For Uber’s data scientists, the process of installing TensorFlow was made even more challenging by the fact that different teams were using different releases of the software. The team wanted to find a way to make it easier for all teams to use the ring-allreduce algorithm, without requiring them to upgrade to the latest version of TensorFlow or apply patches to their existing versions. The solution was to create a stand-alone package called Horovod. This package allowed the team to cut the time required to install TensorFlow from about an hour to a few minutes, depending on the hardware. As a result, Horovod has made it possible for Uber’s data scientists to spend less time installing software and more time doing what they do best. Oracle AI Oracle AI is a suite of artificial intelligence services that can be used to build, train and deploy models. The services include natural language processing, chat bots / customer support, text-to-speech, speech-to-text, object detection for images and data mining. Oracle AI offers pre-configured vms with access to GPUs. The service can be used to build models for anomaly detection, analytics and data mining. Oracle AI is a powerful tool that can be used to improve your business. Children’s Medical Research Institute (CMRI) is a not-for-profit organisation dedicated to improving the health of children through medical research. CMRI moved to Oracle Cloud Infrastructure (OCI) as its preferred cloud platform. This move has helped the institute take advantage of big data and machine learning capabilities to automate routine database tasks, database consolidation, operational reporting, and batch data processing. Overall, the switch to OCI has been a positive move for CMRI, and one that is sure to help the institute continue its important work. H2O H2O is a powerful open source AI platform that is used by companies all over the world to improve their customer support, marketing, and data mining efforts. The software provides a wide range of features that make it easy to collect and analyze customer data, identify anomalies, and create chat bots that can provide an engaging customer experience. H2O is constantly evolving, and the company behind it is always introducing new features and improvements. For example, it can be used to create an intelligent cash management system that predicts cash demand and helps to optimize ATM operations. It can also help information security teams reduce risk by identifying potential threats and vulnerabilities in real time. In addition, H2O.AI can be used to transform auditing from quarterly to real-time, driving audit quality, accuracy and reliability. Alibaba Cloud Alibaba Cloud is a leading provider of cloud computing services. Its products include machine learning, natural language processing, data mining, and analytics. Alibaba Cloud’s machine learning platform offers a variety of pre-created algorithms that can be used for tasks such as data mining, anomaly detection, and predictive maintenance. The platform also provides tools for training and deploying machine learning models. Alibaba Cloud’s natural language processing products offer APIs for text analysis, voice recognition, and machine translation. The company’s data mining and analytics products provide tools for exploring and analyzing data. Alibaba Cloud also offers products for security, storage, and networking. Alibaba, the world’s largest online and mobile commerce company, uses intelligent recommendation algorithms to drive sales using personalized customer search suggestions on its Tmall homepage and mobile app. The system takes into account a customer’s purchase history, browsing behavior, and social interactions when making recommendations. Alibaba has found that this approach leads to increased sales and higher customer satisfaction. In addition to search suggestions, the system also provides personalized product recommendations to customers based on their past behavior. This has resulted in increased sales and engagement on the platform. Alibaba is constantly tweaking and improving its algorithms to ensure that it is providing the most relevant and useful data to its users. IBM Watson IBM Watson is a powerful artificial intelligence system that has a range of applications in business and industry. One of the most important functions of Watson is its ability to process natural language. This enables it to understand human conversation and respond in a way that sounds natural. This capability has been used to develop chatbots and customer support systems that can replicate human conversation. In addition, Watson’s natural language processing capabilities have been used to create marketing campaigns that can target specific demographics. Another key application of Watson is its ability to detect anomalies. This makes it an essential tool for monitoring systems and identifying potential problems. As a result, IBM Watson is a versatile and valuable artificial intelligence system with a wide range of applications. IBM Watson is employed in nearly every industry vertical, as well as in specialized application areas such as cybersecurity. This technology is often used by a company’s data analytics team, but Watson has become so user friendly that it is also easily used by end users such as physicians or marketers. Azure AI Azure AI is a suite of services from Microsoft that helps you build, optimize, train, and deploy models. You can use it for object detection in images and video, natural language processing, chatbots and customer support, text-to-speech, speech-to-text, data mining and analytics, and anomaly detection. Azure AI also provides pre-configured virtual machines so you can get started quickly and easily. Whether you’re an experienced data scientist or just getting started with machine learning, Azure AI can help you achieve your goals. With the rapid pace of technological advancement, it is no surprise that the aviation industry is constantly evolving. One of the leading companies at the forefront of this change is Airbus. The company has unveiled two new innovations that utilize Azure AI solutions to revolutionize pilot training and predict aircraft maintenance issues. Google AI Google AI is a broad set of tools and services that helps you build, deploy, and train models, as well as to take advantage of pre-trained models. You can use it to detect objects in images and video, to perform natural language processing tasks such as chat bots or customer support, to translate text, and to convert text-to-speech or speech-to-text. Additionally, Google AI can be used for data mining and analytics, as well as for anomaly detection. All of these services are hosted on Google Cloud Platform, which offers a variety of options for GPU-accelerated computing, pre-configured virtual machines, and TensorFlow hosting. UPS and Google Cloud Platform were able to develop routing software that has had a major impact on the company’s bottom line. The software takes into account traffic patterns, weather conditions, and the location of UPS facilities, in order to calculate the most efficient route for each driver. As a result, UPS has saved up to $400 million a year, and reduced its fuel consumption by 10 million gallons. In addition, the software has helped to improve customer satisfaction by ensuring that packages are delivered on time. AWS AI Amazon Web Services offers a variety of AI services to help developers create intelligent applications. With pre-trained models for common use cases, AWS AI makes it easy to get started with machine learning. For images and video, the object detection service provides accurate labels and coordinates. Natural language processing can be used for chat bots and customer support, as well as translation. Text-to-speech and speech-to-text are also available. AI powered search provides relevant results from your data. Pattern recognition can be used for code review and monitoring. And data mining and analytics can be used for anomaly detection. AWS AI also offers hosted GPUs and pre-configured vms. With so many powerful features, Amazon Web Services is the perfect platform for developing AI applications. Formula 1 is the world’s most popular motorsport, with hundreds of millions of fans worldwide. The sport has been at the forefront of technological innovation for decades, and its use of data and analytics has been central to its success. Teams have long used on-premises data centers to store and process large amounts of data, but the sport is now accelerating its transformation to the cloud. Formula 1 is moving the vast majority of its infrastructure to Amazon Web Services (AWS), and standardizing on AWS’s machine-learning and data-analytics services. This will enable Formula 1 to enhance its race strategies, data tracking systems, and digital broadcasts through a wide variety of AWS services—including Amazon SageMaker, AWS Lambda, and AWS’s event-driven serverless computing service. By using these services, Formula 1 will be able to deliver new race metrics that will change the way fans and teams experience racing. Conclusion Choosing the right AI development tool can be difficult. This article has provided a comparison of some of the most popular tools on the market. Each tool has its own strengths and weaknesses, so it is important to decide which one will best suit your needs. *i*es L*i*es *e.js Consulting DevOps, SRE & Cloud Consul*ent & Code Re* for Software Developers * Building Complex Apps with A*.",
    "url": "https://blog.risingstack.com/ai-development-tools-compared/"
  },
  {
    "text": "* & Consulting De*nsul*ent & Code Reviews Trainings & Education Trainings Why learn from us? * ** & Consulting De*nsul*ent & Code Reviews Trainings & Education Trainings Why learn from us? * *ngular Node.js Fundamentals Mammogram Analysis with AI and User-Friendly Interfaces Last updated: April 25, 2023 *e.js Consulting De*ting 24.7 Node.js Support Infrastructu*i*es Learn more at risingstack.com * In this article: Janos Kubisch We are excited to share a new project we have been working on in collaboration with Hungary’s leading medical research university – Semmelweis. This project focuses on using artificial intelligence and image recognition technologies to improve the accuracy and efficiency of breast cancer screenings. The Power of AI in Detecting Breast Cancer Early detection and prevention are crucial in the fight against breast cancer, and recent advancements in technology have made it possible for healthcare workers to receive computer assistance in examining mammograms and identifying problematic areas. The integration of machine learning and image recognition technologies in the medical field has the potential to revolutionize breast cancer screening, making it more accurate and efficient. However, the widespread adoption of these artificial intelligence-based solutions will not be possible without good products with great user experience. A user-friendly interface will make it easier for healthcare workers to use these technologies and improve patient outcomes, making it a crucial component in the fight against breast cancer. As a recognized leader in medical research, Semmelweis University has a long-standing reputation for producing cutting-edge advancements in the field. We are proud to have the opportunity to partner with such an esteemed institution and contribute to their ongoing efforts to improve medical outcomes and advance the field of medicine. Implementing AI with a User-Friendly Interface The primary objective of this project was to make the workings of the algorithm more visually accessible to medical professionals. The goal was to design a platform that could be run on any device with network connectivity, either through a standalone application or using Docker technology. This would allow us to demonstrate the algorithm’s capabilities on-site, making it easier for those considering its use to get a hands-on understanding of its capabilities. During the image processing and annotation stage, the application provides real-time feedback in the form of a visual animation and progress bar. This helps users keep track of the analysis as it progresses and gives them a sense of the speed and efficiency of the algorithm. Once all the images have been processed, the application highlights those that show an increased risk, based on the annotations, in an interactive gallery. This gallery provides a clear and easy-to-understand representation of the algorithm’s results, making it a valuable tool for both users and potential adopters. The software is intentionally slowed down for presentation purposes. It’s much, much faster, of course. The Algorithm: Using Faster-RCNN and VGG16 The image detection algorithm at the core of this project uses a state-of-the-art region-based deep convolutional neural network called Faster-R-CNN. This powerful model was specifically designed for object detection and proved to be an effective tool for identifying problematic regions in mammograms. The base network used in the model was VGG16, a highly regarded 16-layer deep convolutional neural network that can be easily obtained from the PyTorch website. To make the algorithm even more effective, we further trained it to detect two different types of objects in mammogram images: benign and malignant lesions. The output of the algorithm is not just a simple diagnosis, but a comprehensive report that includes a score reflecting the confidence level in the diagnosis for each detected lesion. The algorithm also generates a modified image that clearly highlights the locations of the detected lesions by overlaying bounding boxes on the original mammogram. This makes it easy for healthcare workers to understand and interpret the results of the analysis. The Backend – Frontend Integration The backend is responsible for managing the running of the algorithm and ensuring that the results are promptly sent to the frontend once the analysis of an image is completed. The input images are first sent to the frontend, where they are overlaid with a scanline animation, providing a visual indication that the analysis is underway. As soon as the results are available, they are displayed on the frontend as a simple red/green overlay and a small animation before transitioning to the next image. To avoid any potential performance issues, the algorithm is run in serial for all images, as running it in parallel would quickly cause problems when using only the CPU and system memory. However, the CUDA Python SDK provides the ability to automatically use the CPU if a dedicated GPU cannot be found, making it possible to use the algorithm even on basic devices, albeit with reduced efficiency. When a suitable nVidia GPU is available, the algorithm can be run in larger batches, providing much faster results. To get the results back to the frontend, we used Socket.io, as it allows for real-time communication between the backend and frontend, allowing us to directly push data from the backend to the frontend as soon as the algorithm finishes processing an image. The images that have a confidence score below a certain threshold are considered “negative,” indicating that they are likely healthy. These images are presented in a distinctive way, with a small scale-out-scale-in animation. This animation is achieved through the use of CSS animation, utilizing the scale transform function. Deploying the Application with Docker The entire application is packaged in a docker image, making it more accessible and easier to run and distribute. This approach has a number of advantages, one of which is the ability to deploy the application to a cloud service, which opens up the possibility of accessing it from anywhere with an internet connection. However, it is important to consider the architecture of the system you will run the application on, as this can impact which base image you will choose. For example, on M1 Macs, arm64 images are required, and attempting to run other images may result in errors. By utilizing a docker image, the project benefits from the portability and compatibility provided by this technology, allowing for seamless deployment and usage across different platforms. Node, Express and React under the hood In the implementation of this project, we chose to utilize a combination of Node.js and Express for the backend and React for the frontend. This choice was made based on the strengths and capabilities of these technologies, which provided the ideal foundation for the application’s needs. However, it is worth noting that this design may not be the only possible solution, and the application could also be implemented as an Electron app, which is a popular framework for creating desktop applications. This versatility highlights the flexibility of the project and its ability to adapt to different environments and technologies. The key is to find the right tool for the job, and in this case, we found that Node.js, Express, and React provided the optimal solution for our needs. How RisingStack can help with your AI project As businesses and corporations look to harness the power of Artificial Intelligence, there’s a growing demand for software development companies that can help implement these AI models and create web-based user interfaces to accompany them. That’s where RisingStack can help you. In the past couple of months, we created several custom AI solutions for businesses and institutions of all sizes, just to name a few: Using AI to automatically generate product names and descriptions for webshop engines. Creating easy-read text for children with disabilities Sentiment analysis and automatic answers in the hospitality industry. Pinpointing breast cancer using neural networks. Whether you’re looking to create a custom AI model to help streamline your business processes, or you’re looking to build a web-based UI that provides users with a more engaging and interactive experience, we have the skills and expertise *. Get in touch with us to learn more about how we can help you implement AI models and create web-based UI-s that drive results for your business. *i*es L*i*es *e.js Consulting DevOps, SRE & Cloud Consul*ent & Code Re* for Software Developers * Building Complex Apps with A*.",
    "url": "https://blog.risingstack.com/ai-healthcare-semmelweis-risingstack-case-study/"
  }
]
